# CS294/194-196 LLM Agent: 5. Compound AI Sys & DSPy Framework

## 왜 복합 AI 시스템(Compound AI Systems)인가?
단일 모델(Monolithic LM)만으로는 신뢰할 수 있는 AI 시스템을 구축하는 데 한계가 있기 때문에, 최근 연구자들은 LM을 특화된 구성 요소로 사용하는 모듈형 프로그램인 '복합 AI 시스템'을 구축하고 있습니다. 복합 AI 시스템이 필요한 주요 이유는 다음과 같습니다.

- 품질(Quality) 및 신뢰성: 더 나은 범위를 가진 LM 기능을 안정적으로 조합하여 시스템의 전반적인 품질을 높일 수 있습니다.
- 제어 가능성(Control): 도구를 통해 시스템을 접지(Grounding)하고 반복적으로 개선할 수 있는 제어권을 가집니다.
- 투명성(Transparency): 시스템의 실행 궤적을 디버깅하고, 사용자에게 답변의 근거(Attribution)를 제공할 수 있습니다.
- 효율성(Efficiency): 지식 저장이나 제어 흐름을 외부로 분리함으로써, 더 작고 효율적인 LM을 사용할 수 있습니다.
- 추론 시간 확장(Inference-time Scaling): 추론 시점에 더 나은 출력을 찾기 위해 체계적인 검색(Systematic search)을 수행할 수 있습니다.

## 기존 복합 AI 시스템의 문제점
기존의 복합 AI 시스템들은 원칙적으로는 모듈형이지만, 실제 구현 방식에서는 심각한 문제를 안고 있습니다.

- "Stringly-typed" 문제: 시스템의 근본적인 아키텍처가 부수적인 선택 사항(특정 프롬프트 문자열 등)과 복잡하게 결합되어 있습니다.
- 취약한 프롬프트 의존성: LM은 지시 방식에 매우 민감하여, 개발자들은 이를 제어하기 위해 수천 토큰에 달하는 긴 프롬프트를 작성하게 됩니다.
- 이식성(Portability) 부재: 특정 LM이나 파이프라인에 맞춰진 프롬프트는 새로운 모델이나 목표에 재사용하기 어렵습니다.
- 역할의 혼재: 하나의 프롬프트 안에 시그니처(입출력 동작), 예측기(추론 전략), 어댑터(포맷팅), 메트릭, 최적화 도구 등 서로 다른 5가지 역할이 뒤섞여 있어 관리가 불가능합니다.

## DSPy (Declaratively Self-improving Python)의 정의와 구조
DSPy는 복합 AI 시스템을 모듈형 프로그램으로 정의하고, 이를 데이터를 통해 스스로 개선할 수 있도록 돕는 프레임워크입니다. DSPy는 언어 모델(LM)을 사용하는 방식을 수동적인 ‘쪽지(프롬프트) 보내기’에서 체계적인 ‘소프트웨어 아키텍처’인 프로그래밍으로 전환합니다.

- 핵심 철학: 개발자가 언어 모델에게 "어떻게(How)" 프롬프트를 작성할지 고민하는 대신, 시스템이 "무엇을(What)" 수행해야 하는지 "선언적(Declarative)"으로 정의하는 데 집중하게 합니다.
- 상세: DSPy 프로그램은 PyTorch와 유사한 구조를 가집니다.
  - 시그니처 (Signatures): 모듈의 입출력 동작을 정의하는 자연어 타입 시스템입니다 (예: context, question -> answer).
  - 모듈 (Modules): ChainOfThought나 Retrieve와 같이 시그니처를 실현하기 위한 구체적인 추론 전략을 캡슐화한 범용 레이어입니다.
  - 최적화 도구 (Optimizers): 사용자가 설정한 메트릭(Metric)과 훈련 데이터를 바탕으로, 각 모듈의 프롬프트 문자열이나 모델의 가중치를 자동으로 튜닝합니다.

## "프로그래밍으로서의 AI (Natural Language Programming)"
DSPy는 우리가 시스템을 제어하고 모듈식으로 개선하는 방법을 이미 알고 있으며, 그것을 '프로그래밍'이라고 부른다고 강조합니다.

- 추상화와 컴파일러: DSPy는 AI 시스템을 자연어 타입을 가진 모듈식 프로그램으로 추상화합니다. 이는 마치 C 코드를 작성하면 컴파일러가 다양한 CPU 아키텍처에 맞는 기계어로 변환해주듯, DSPy 최적화 도구가 고수준의 논리 코드를 특정 언어 모델에 최적화된 저수준 프롬프트로 '컴파일'하는 것과 같습니다.
- 취약한 프롬프트에서의 해방: 기존 시스템은 프롬프트 문자열 하나만 바뀌어도 전체 시스템이 무너지는 "Stringly-typed" 문제를 안고 있었습니다. 하지만 프로그래밍 방식 도입을 통해 시스템의 논리 구조와 구체적인 구현(프롬프트)을 분리함으로써, 모델이 바뀌어도 코드를 재사용할 수 있는 이식성(Portability)을 확보하게 됩니다.
- 패러다임의 변화: 수동적인 프롬프트 엔지니어링에서 최적화된 프로그램(Optimized Programs)으로의 진화를 의미합니다. 개발자는 더 이상 문자열을 만지작거리는 것이 아니라, 프로그램의 흐름을 설계하고 최적화 도구가 더 나은 결과를 찾도록 유도합니다.

```
for hop in range(2):라는 파이썬 루프를 사용하여 두 번의 검색 과정을 거치는 로직을 명확하게 프로그래밍

dspy.ChainOfThought("context, question -> query")라고 작성하면, 이는 "컨텍스트와 질문을 입력받아 검색 쿼리를 출력한다"는 함수의 타입(입출력 사양)을 정의하는 것과 같습
 ```

## Optimizing Instructions and Demonstrations for Multi-stage Language Model Programs
단계 언어 모델 프로그램(Multi-stage Language Model Programs)의 지시문과 예시를 최적화하는 연구입니다. 즉, 이 연구는 여러 개의 모듈형 LM 호출이 복잡한 파이프라인으로 연결된 'LM 프로그램'의 성능을 최적화하는 것을 목표로 합니다. 개발자가 작성한 프로그램 구조(코드)와 최적화하려는 메트릭(Metric), 그리고 소량의 훈련 데이터가 주어졌을 때, 각 모듈의 프롬프트 변수(지시문 및 few-shot 예시)에 가장 적합한 문자열을 할당하여 전체 시스템의 성능을 극대화하는 것입니다.

### Constraints / Assumptions (제약 조건 및 가정)
실제 개발 환경을 반영하여 다음과 같은 까다로운 제약을 가정합니다:
- 모델 내부 접근 불가: 모델의 가중치나 로그 확률(log-probs)에 접근할 수 없는 API 기반 모델을 상정합니다.
- 중간 단계 라벨 부재: 파이프라인의 중간 단계에 대한 수동 정답 라벨이나 메트릭이 없으며, 전체 시스템의 최종 결과물에 대한 점수만 알 수 있습니다.
- 제한된 예산: 훈련 데이터의 양과 LM 호출 횟수를 최소화하여 비용 효율적인 최적화를 지향합니다.

### Key Challenges (핵심 과제)
1. Prompt Proposal (프롬프트 제안)
가능한 모든 문자열 조합을 탐색하는 것은 불가능합니다. 따라서 작업, 프로그램, 데이터의 특성을 반영한 고품질의 프롬프트 후보군을 효율적으로 생성하는 것이 필수적입니다.
2. Credit Assignment (기여도 할당)
여러 모듈이 섞여 있을 때, 전체 성능 향상이나 저하가 어떤 모듈의 프롬프트 때문인지 판별하기 어렵습니다. 각 모듈의 변수가 최종 성능에 미치는 영향을 정확히 추론해야 탐색 효율을 높일 수 있습니다.

### # Methods (최적화 방법론)
#### Bootstrap Few-shot
훈련 데이터를 프로그램에 입력하여 실행 궤적(trace)을 추적합니다. 이때 최종 메트릭 점수가 높은 성공적인 사례의 중간 단계 입출력을 해당 모듈의 few-shot 예시(demonstration)로 수집하는 기법입니다. 이후 랜덤 서치를 통해 최적의 예시 조합을 찾습니다.

- 원리: 훈련 데이터를 프로그램에 입력하여 실행할 때, 모든 모듈의 입출력을 기록합니다. 만약 프로그램의 최종 결과물이 설정한 메트릭(Metric)을 만족(예: 정답과 일치)한다면, 그 과정에 포함된 모든 중간 단계의 입출력 쌍을 해당 모듈의 유효한 '시연(Demonstration)' 예시로 간주하여 저장합니다.
- 최적화: 이렇게 수집된 예시들 중 최적의 조합을 찾기 위해 "랜덤 서치(Random Search)"를 수행하여 전체 성능이 가장 높은 예시 세트를 선택합니다.
- 예시: 멀티홉 질문 답변 시스템에서 "데이비드 그레고리가 상속받은 성의 층수는?"이라는 질문에 대해, 시스템이 1단계에서 "데이비드 그레고리 상속 성"이라는 쿼리를 생성하고 2단계에서 올바른 층수를 찾아냈다면, 1단계에서 생성한 쿼리는 generate_query 모듈의 훌륭한 few-shot 예시가 됩니다.

#### Extending OPRO (OPRO 확장)
기존의 단일 프롬프트 최적화 기법인 OPRO를 다단계 프로그램으로 확장한 방식입니다.

- 원리: 제안 모델(Proposer LM)에게 지금까지 시도했던 지시문들과 그에 따른 성능 점수 이력(History)을 보여줍니다. 제안 모델은 이 이력을 바탕으로 "어떤 지시문이 성능을 높였는지" 추론하여 더 나은 새로운 지시문을 생성합니다.

- 주요 변형:
  - Module-Level OPRO: 프로그램 전체 점수가 각 모듈 지시문의 품질을 대변한다고 가정하고, 모든 모듈의 지시문을 동시에 독립적으로 업데이트합니다.
  - Program-Level OPRO: 제안 모델이 프로그램의 모든 단계와 이력을 한꺼번에 보고, 모듈 간의 상호작용을 고려하여 기여도(Credit)를 할당하고 지시문을 수정합니다.
  - CA-OPRO (Coordinate-Ascent): 한 번에 하나의 모듈만 수정하고 나머지는 고정하는 방식으로 최적화하지만, 비용이 매우 많이 듭니다.

- 예시: 처음에는 "단계별로 생각해보세요"라는 지시문으로 점수 31점을 받았다면, 이력을 본 제안 모델이 "심호흡을 하고 단계별로 논리적으로 생각해보세요"라고 수정하여 42점을 받는 식으로 개선해 나갑니다.

#### MIPRO (Multi-prompt Instruction PRoposal Optimizer)
MIPRO는 지시문과 예시를 동시에(Jointly) 최적화하며, 베이지안 최적화(Bayesian Optimization)를 도입한 가장 정교한 도구입니다.
- 원리
  - 접지(Grounding): 지시문을 제안할 때 단순히 점수만 주는 것이 아니라, 데이터셋의 특성 요약, 프로그램 코드 구조, 성공했던 실행 예시(Bootstrap demos) 등을 문맥으로 제공하여 매우 구체적인 후보를 만듭니다.
  - 베이지안 대리 모델(Surrogate Model): 수많은 지시문 후보와 예시 세트 조합 중 어떤 것이 가장 유망한지 예측하는 확률 모델을 학습합니다.
  - 효율적 탐색: 전체 데이터를 다 평가하는 대신 미니배치(Mini-batch) 단위로 평가하여 자원을 절약하면서도 노이즈에 강한 최적의 조합을 찾아냅니다.
- 예시: 의료 상담 AI 시스템을 최적화할 때, MIPRO는 데이터셋 요약을 통해 "이 데이터는 전문적인 의학 용어를 포함함"을 인지하고, 성공 예시를 참고하여 "환자의 증상을 의학적 관점에서 요약하고 진단명을 제안하라"는 정교한 지시문을 생성한 뒤, 베이지안 모델을 통해 이 지시문과 가장 잘 어울리는 few-shot 예시 조합을 찾아냅니다.

### Experiments and Results (실험 및 결과)
연구진은 LangProBe라는 벤치마크를 통해 HotPotQA, ScoNe, HoVer 등 7개 과제에서 성능을 검증했습니다.
- MIPRO의 우수성: MIPRO는 7개 과제 중 5개에서 기존 베이스라인을 압도했으며, 최대 13%의 정확도 향상을 보였습니다.

#### 예시 최적화의 힘 (The Power of Example Optimization)
실험 결과에 따르면, 대부분의 과제에서 성공적인 실행 궤적을 부트스트래핑(Bootstrapping)하여 few-shot 예시로 활용하는 것이 성능 향상의 가장 결정적인 요인으로 나타났습니다.

- 지시문 최적화 압도: 대다수의 작업에서 부트스트랩된 예시만 최적화하는 것이 지시문만 최적화하는 것보다 훨씬 더 높은 성능을 보였습니다. 통계적 검증 결과, 단순한 '부트스트랩 랜덤 서치'가 지시문 전용 최적화 도구보다 뛰어난 성능을 기록한 사례가 많았습니다.
- 추론 동작의 전수: 강력한 부트스트랩 예시는 단순한 작업 형식(Format)을 가르치는 것을 넘어, 성공적인 추론 동작(Reasoning behavior)에 대한 구체적인 정보를 모델에 제공합니다.
- 높은 변동성과 선택의 중요성: 어떤 예시 세트를 선택하느냐에 따라 성능 변동이 매우 컸습니다. 이는 단순히 예시를 넣는 것이 아니라, '올바른' 예시 조합을 찾아내는 최적화 과정이 필수적임을 의미합니다.

#### 지시문의 역할 (The Role of Instructions)
지시문 최적화는 예시만으로는 해결하기 어려운 복잡한 논리나 명시적인 규칙이 필요한 상황에서 핵심적인 역할을 수행합니다.

- 조건부 규칙(Conditional Rules) 처리: 몇 개의 예시만으로는 모든 패턴을 파악하기 어려운 복잡한 조건부 규칙이 포함된 작업(예: HotPotQA Conditional)에서 지시문 최적화의 위력이 발휘됩니다. 이런 경우, 지시문 최적화가 예시 전용 최적화보다 더 높은 점수를 기록하기도 했습니다.
- 초기 프롬프트 오류 수정: 사용자가 초기에 잘못 설정한 프롬프트(예: 오타가 포함된 Iris-Typo)가 있을 때, 지시문 최적화 도구는 이를 감지하고 올바른 방향으로 수정하여 성능을 복구하는 역할을 합니다.
- 맥락 제공(Grounding): 데이터셋의 요약이나 프로그램의 구조적 특징을 지시문에 반영함으로써, 모델이 작업의 전체적인 맥락을 더 잘 이해하도록 돕습니다.

### Summary and Lessons (요약 및 교훈)
- Natural Language Programming: 복잡한 프롬프트 엔지니어링 대신, 선언적인 프로그램 구조와 자동화된 최적화 도구를 사용하는 것이 더 정확하고 제어 가능하며 투명합니다.
- Show, don't tell: 많은 작업에서 단순히 지시문을 고치는 것보다, 성공적인 실행 예시(Bootstrapped Demonstrations)를 자동으로 생성하여 제공하는 것이 성능 향상에 훨씬 효과적이다.
- 예시 선택의 높은 변동성: 어떤 부트스트랩 예시 세트를 선택하느냐에 따라 성능 차이가 매우 크게 나타나며, 이는 단순한 무작위 선택보다 체계적인 탐색이 중요함을 시사합니다.
- 지시문의 결정적 역할: 예시만으로는 학습하기 어려운 복잡한 조건부 규칙(Conditional rules)이나 미묘한 패턴이 포함된 작업에서는 지시문 최적화가 필수적입니다.
- 결합 최적화의 승리 (MIPRO): 지시문과 예시를 개별적으로 최적화하기보다, MIPRO와 같이 두 요소를 동시에 최적화하는 것이 대부분의 과제에서 가장 높은 성과를 냅니다.
- 접지(Grounding)와 기여도 할당의 필요성: 최적화 도구가 더 나은 프롬프트를 제안하기 위해서는 데이터와 프로그램에 대한 맥락 정보(접지)가 필요하며, 여러 모듈 중 어떤 것이 성능에 기여했는지 판별하는 기여도 할당(Credit Assignment) 기술이 중요합니다.